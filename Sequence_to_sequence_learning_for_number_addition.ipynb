{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/My_Neural_Network_Architecture/blob/main/Sequence_to_sequence_learning_for_number_addition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sequence to sequence learning for performing number addition**"
      ],
      "metadata": {
        "id": "D-GQXT-pEJmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we train a model to learn to add two numbers, provided as strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- Input: \"535+61\"\n",
        "- Output: \"596\"\n",
        "\n",
        "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
        " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
        "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf).\n",
        "\n",
        "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
        " source and target for this problem.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "For two digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
        "\n",
        "Three digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
        "\n",
        "Four digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
        "\n",
        "Five digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
      ],
      "metadata": {
        "id": "LiZItu4_OaxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ],
      "metadata": {
        "id": "IFQvy4FdEIvd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the data"
      ],
      "metadata": {
        "id": "5saZpHi2Ofoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)"
      ],
      "metadata": {
        "id": "EET2mBYEEnrl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkV9QfKwErjo",
        "outputId": "de84a85c-ed03-4c22-d5a1-a439825b6475"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctable.decode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZDvRtW9GQmT",
        "outputId": "d6b84113-63d1-4385-c04f-0780e245e6e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method CharacterTable.decode of <__main__.CharacterTable object at 0x7aa1358010f0>>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize the data"
      ],
      "metadata": {
        "id": "FuZJ_lJSOlZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectorization...\")\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ZIAfEhHzrW",
        "outputId": "b1cb195e-a682-4fd7-f57d-09f36819601a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.Input((MAXLEN, len(chars))))\n",
        "model.add(layers.LSTM(128))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xDyUv9TJR0V",
        "outputId": "27ad1d3a-2f17-45dd-d947-7387f86201b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVecto  (None, 4, 128)            0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4, 12)             1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205324 (802.05 KB)\n",
            "Trainable params: 205324 (802.05 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9orwo2fnLNKp",
        "outputId": "63876b8d-2f19-4d82-dd0e-1a10e0733da1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 19s 8ms/step - loss: 1.7619 - accuracy: 0.3549 - val_loss: 1.5580 - val_accuracy: 0.4193\n",
            "1/1 [==============================] - 1s 652ms/step\n",
            "Q 608+15  T 623  ☒ 662 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 234+0   T 234  ☒ 334 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 0+23    T 23   ☒ 33  \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 25+25   T 50   ☒ 10  \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 105+6   T 111  ☒ 110 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 336+90  T 426  ☒ 332 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 435+429 T 864  ☒ 118 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 54+47   T 101  ☒ 10  \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 819+56  T 875  ☒ 902 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 517+73  T 590  ☒ 782 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3220 - accuracy: 0.5056 - val_loss: 1.1438 - val_accuracy: 0.5725\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 86+147  T 233  ☒ 216 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 872+95  T 967  ☒ 972 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 232+680 T 912  ☒ 997 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 268+2   T 270  ☒ 266 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 982+78  T 1060 ☒ 1042\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 463+53  T 516  ☒ 511 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 173+778 T 951  ☒ 901 \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 76+156  T 232  ☒ 216 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 37+563  T 600  ☒ 596 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 217+20  T 237  ☒ 226 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0185 - accuracy: 0.6212 - val_loss: 0.9357 - val_accuracy: 0.6432\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 9+596   T 605  ☒ 597 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 45+273  T 318  ☒ 317 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 297+47  T 344  ☒ 337 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 108+7   T 115  ☒ 111 \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Q 6+492   T 498  ☒ 497 \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 665+586 T 1251 ☒ 1245\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 467+71  T 538  ☒ 537 \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Q 82+73   T 155  ☒ 140 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 291+72  T 363  ☒ 367 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 412+62  T 474  ☒ 477 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8494 - accuracy: 0.6869 - val_loss: 0.8159 - val_accuracy: 0.6945\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Q 29+615  T 644  ☒ 645 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 17+811  T 828  ☒ 820 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 785+834 T 1619 ☒ 1725\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 468+24  T 492  ☒ 497 \n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 80+25   T 105  ☑ 105 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 403+324 T 727  ☒ 730 \n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 942+78  T 1020 ☒ 1015\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 292+61  T 353  ☒ 355 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 679+896 T 1575 ☒ 1563\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 51+79   T 130  ☒ 133 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.7671 - accuracy: 0.7173 - val_loss: 0.7378 - val_accuracy: 0.7273\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 66+73   T 139  ☒ 134 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 1+84    T 85   ☒ 83  \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 36+975  T 1011 ☒ 1008\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 34+866  T 900  ☒ 898 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 436+77  T 513  ☒ 518 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 570+5   T 575  ☑ 575 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 56+417  T 473  ☒ 471 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 875+946 T 1821 ☒ 1829\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 170+525 T 695  ☒ 792 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 81+720  T 801  ☒ 804 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.7110 - accuracy: 0.7384 - val_loss: 0.7194 - val_accuracy: 0.7273\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 18+901  T 919  ☒ 911 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 81+37   T 118  ☒ 115 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 239+2   T 241  ☑ 241 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 477+581 T 1058 ☒ 1063\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 652+862 T 1514 ☑ 1514\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 927+43  T 970  ☒ 961 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 45+273  T 318  ☒ 317 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 519+33  T 552  ☒ 550 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 323+67  T 390  ☒ 384 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 27+938  T 965  ☒ 968 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.6610 - accuracy: 0.7567 - val_loss: 0.6345 - val_accuracy: 0.7668\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 679+562 T 1241 ☑ 1241\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 991+556 T 1547 ☒ 1540\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 150+53  T 203  ☒ 208 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 283+435 T 718  ☒ 719 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 55+923  T 978  ☒ 974 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 914+84  T 998  ☒ 990 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 66+420  T 486  ☒ 481 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 64+274  T 338  ☒ 339 \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Q 534+31  T 565  ☒ 564 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 300+39  T 339  ☒ 337 \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.5614 - accuracy: 0.7913 - val_loss: 0.4572 - val_accuracy: 0.8266\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 468+14  T 482  ☒ 481 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 10+784  T 794  ☑ 794 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 19+832  T 851  ☑ 851 \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 590+598 T 1188 ☒ 1177\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 596+8   T 604  ☒ 605 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 154+1   T 155  ☑ 155 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 422+6   T 428  ☑ 428 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 49+69   T 118  ☒ 116 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 40+456  T 496  ☑ 496 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 20+139  T 159  ☒ 155 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.3230 - accuracy: 0.8880 - val_loss: 0.2250 - val_accuracy: 0.9270\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 747+8   T 755  ☑ 755 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 101+66  T 167  ☑ 167 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 738+890 T 1628 ☒ 1629\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Q 61+978  T 1039 ☑ 1039\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 284+139 T 423  ☒ 422 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 61+728  T 789  ☒ 799 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 73+646  T 719  ☑ 719 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 555+4   T 559  ☑ 559 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 573+770 T 1343 ☑ 1343\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Q 169+46  T 215  ☑ 215 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.1611 - accuracy: 0.9558 - val_loss: 0.1161 - val_accuracy: 0.9712\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 14+683  T 697  ☑ 697 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 671+9   T 680  ☑ 680 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 423+664 T 1087 ☑ 1087\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 560+492 T 1052 ☒ 1053\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 3+229   T 232  ☑ 232 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 879+395 T 1274 ☑ 1274\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Q 607+829 T 1436 ☑ 1436\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 98+463  T 561  ☑ 561 \n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Q 90+804  T 894  ☑ 894 \n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Q 81+904  T 985  ☑ 985 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0957 - accuracy: 0.9753 - val_loss: 0.0788 - val_accuracy: 0.9785\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 516+865 T 1381 ☑ 1381\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 982+423 T 1405 ☑ 1405\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 210+39  T 249  ☑ 249 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 826+664 T 1490 ☑ 1490\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 4+216   T 220  ☑ 220 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 327+373 T 700  ☑ 700 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 651+26  T 677  ☑ 677 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 980+24  T 1004 ☑ 1004\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 534+31  T 565  ☑ 565 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 93+88   T 181  ☑ 181 \n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0723 - accuracy: 0.9802 - val_loss: 0.1339 - val_accuracy: 0.9524\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 55+162  T 217  ☑ 217 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 685+61  T 746  ☑ 746 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 79+219  T 298  ☑ 298 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 85+83   T 168  ☒ 158 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 145+222 T 367  ☒ 366 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 81+87   T 168  ☒ 158 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 45+413  T 458  ☑ 458 \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Q 994+78  T 1072 ☑ 1072\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 50+29   T 79   ☑ 79  \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 792+0   T 792  ☑ 792 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0468 - accuracy: 0.9879 - val_loss: 0.0712 - val_accuracy: 0.9761\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 669+601 T 1270 ☑ 1270\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 954+68  T 1022 ☑ 1022\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 9+890   T 899  ☑ 899 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 4+958   T 962  ☒ 972 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 372+598 T 970  ☑ 970 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 92+421  T 513  ☑ 513 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 2+263   T 265  ☑ 265 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 113+91  T 204  ☑ 204 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 499+0   T 499  ☑ 499 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 566+59  T 625  ☑ 625 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.0515 - val_accuracy: 0.9837\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 539+75  T 614  ☑ 614 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 181+673 T 854  ☑ 854 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 58+310  T 368  ☑ 368 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 46+939  T 985  ☑ 985 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 682+43  T 725  ☑ 725 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 619+28  T 647  ☑ 647 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 763+74  T 837  ☑ 837 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 964+946 T 1910 ☑ 1910\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 423+8   T 431  ☑ 431 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 926+75  T 1001 ☑ 1001\n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0380 - accuracy: 0.9899 - val_loss: 0.0329 - val_accuracy: 0.9909\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 583+57  T 640  ☑ 640 \n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Q 6+341   T 347  ☑ 347 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 4+958   T 962  ☑ 962 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 970+5   T 975  ☑ 975 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 92+161  T 253  ☑ 253 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 341+735 T 1076 ☑ 1076\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 219+4   T 223  ☑ 223 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 984+86  T 1070 ☑ 1070\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 74+528  T 602  ☑ 602 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 31+239  T 270  ☑ 270 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0180 - val_accuracy: 0.9956\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 252+400 T 652  ☑ 652 \n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Q 764+887 T 1651 ☑ 1651\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 758+0   T 758  ☑ 758 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 76+497  T 573  ☑ 573 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 744+75  T 819  ☑ 819 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 6+164   T 170  ☑ 170 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 47+586  T 633  ☑ 633 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 42+275  T 317  ☑ 317 \n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Q 30+969  T 999  ☑ 999 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 879+10  T 889  ☑ 889 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.0284 - val_accuracy: 0.9912\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 679+375 T 1054 ☑ 1054\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 875+435 T 1310 ☑ 1310\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 97+47   T 144  ☑ 144 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 35+651  T 686  ☑ 686 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 618+230 T 848  ☑ 848 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 964+946 T 1910 ☑ 1910\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 482+58  T 540  ☑ 540 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 931+26  T 957  ☑ 957 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 821+256 T 1077 ☑ 1077\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 7+125   T 132  ☑ 132 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0152 - val_accuracy: 0.9963\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 69+632  T 701  ☑ 701 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 280+196 T 476  ☑ 476 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 713+30  T 743  ☑ 743 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 57+893  T 950  ☑ 950 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 518+3   T 521  ☑ 521 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 18+550  T 568  ☑ 568 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 871+33  T 904  ☑ 904 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 557+510 T 1067 ☑ 1067\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 126+718 T 844  ☑ 844 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 213+89  T 302  ☑ 302 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 315+250 T 565  ☑ 565 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 965+203 T 1168 ☑ 1168\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 879+67  T 946  ☑ 946 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 969+501 T 1470 ☑ 1470\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 52+335  T 387  ☑ 387 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 816+327 T 1143 ☑ 1143\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 397+87  T 484  ☑ 484 \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Q 30+653  T 683  ☑ 683 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 778+749 T 1527 ☑ 1527\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 748+86  T 834  ☑ 834 \n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.0224 - val_accuracy: 0.9936\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Q 37+148  T 185  ☑ 185 \n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Q 992+670 T 1662 ☒ 1762\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Q 41+834  T 875  ☑ 875 \n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Q 35+409  T 444  ☑ 444 \n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "Q 958+748 T 1706 ☑ 1706\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Q 805+966 T 1771 ☑ 1771\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Q 479+28  T 507  ☑ 507 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 9+373   T 382  ☑ 382 \n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Q 90+11   T 101  ☑ 101 \n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "Q 184+73  T 257  ☑ 257 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0225 - val_accuracy: 0.9929\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 64+80   T 144  ☑ 144 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 354+7   T 361  ☑ 361 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 233+33  T 266  ☑ 266 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 896+0   T 896  ☑ 896 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 453+40  T 493  ☑ 493 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 862+379 T 1241 ☑ 1241\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 735+12  T 747  ☑ 747 \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Q 535+476 T 1011 ☑ 1011\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 3+178   T 181  ☒ 180 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 724+0   T 724  ☑ 724 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 863+70  T 933  ☑ 933 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 577+76  T 653  ☑ 653 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 574+7   T 581  ☑ 581 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 49+78   T 127  ☑ 127 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 1+132   T 133  ☑ 133 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 94+136  T 230  ☑ 230 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 925+348 T 1273 ☑ 1273\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 792+0   T 792  ☑ 792 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 484+492 T 976  ☑ 976 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 753+62  T 815  ☑ 815 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.0129 - val_accuracy: 0.9962\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 862+679 T 1541 ☑ 1541\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Q 7+142   T 149  ☑ 149 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 182+7   T 189  ☑ 189 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 155+58  T 213  ☑ 213 \n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Q 7+879   T 886  ☑ 886 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 375+65  T 440  ☑ 440 \n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Q 198+18  T 216  ☑ 216 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 123+195 T 318  ☑ 318 \n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Q 72+486  T 558  ☑ 558 \n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Q 74+890  T 964  ☑ 964 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 11s 7ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 137+434 T 571  ☑ 571 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 97+364  T 461  ☑ 461 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 357+33  T 390  ☑ 390 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 621+3   T 624  ☑ 624 \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 123+195 T 318  ☑ 318 \n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Q 56+782  T 838  ☑ 838 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 701+4   T 705  ☑ 705 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 941+71  T 1012 ☑ 1012\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 2+565   T 567  ☑ 567 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 331+71  T 402  ☑ 402 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 147+6   T 153  ☑ 153 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 423+8   T 431  ☑ 431 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 8+606   T 614  ☑ 614 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 25+32   T 57   ☑ 57  \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 27+974  T 1001 ☑ 1001\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Q 6+741   T 747  ☑ 747 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 5+169   T 174  ☑ 174 \n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Q 175+626 T 801  ☑ 801 \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 509+35  T 544  ☑ 544 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 332+177 T 509  ☑ 509 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0219 - val_accuracy: 0.9936\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 84+92   T 176  ☑ 176 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 25+326  T 351  ☑ 351 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 47+766  T 813  ☑ 813 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 70+436  T 506  ☑ 506 \n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 5+180   T 185  ☑ 185 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 291+94  T 385  ☑ 385 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 610+912 T 1522 ☒ 1521\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 318+9   T 327  ☑ 327 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 584+950 T 1534 ☑ 1534\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 472+180 T 652  ☑ 652 \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0129 - val_accuracy: 0.9962\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Q 18+444  T 462  ☑ 462 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 900+853 T 1753 ☑ 1753\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 403+2   T 405  ☑ 405 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 867+983 T 1850 ☑ 1850\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 33+491  T 524  ☑ 524 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 9+932   T 941  ☑ 941 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 3+774   T 777  ☑ 777 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 4+813   T 817  ☑ 817 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 298+928 T 1226 ☑ 1226\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 209+28  T 237  ☑ 237 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 70+407  T 477  ☑ 477 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 124+616 T 740  ☑ 740 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 295+8   T 303  ☑ 303 \n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 872+76  T 948  ☑ 948 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 282+65  T 347  ☑ 347 \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Q 243+463 T 706  ☑ 706 \n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Q 458+459 T 917  ☑ 917 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 82+221  T 303  ☑ 303 \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Q 888+719 T 1607 ☑ 1607\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 843+726 T 1569 ☑ 1569\n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0557 - val_accuracy: 0.9838\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 32+616  T 648  ☑ 648 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 203+827 T 1030 ☒ 1020\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 36+850  T 886  ☑ 886 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 579+286 T 865  ☑ 865 \n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 198+18  T 216  ☑ 216 \n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 647+66  T 713  ☑ 713 \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 535+568 T 1103 ☑ 1103\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Q 865+205 T 1070 ☑ 1070\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 28+66   T 94   ☑ 94  \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Q 820+570 T 1390 ☑ 1390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjC69JlAPIOq",
        "outputId": "f2d1ffe5-192a-4c9b-b7b0-0840569a1956"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 30+631  T 661  ☑ 661 \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Q 180+286 T 466  ☑ 466 \n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Q 706+358 T 1064 ☑ 1064\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Q 1+598   T 599  ☑ 599 \n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Q 469+923 T 1392 ☑ 1392\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Q 582+29  T 611  ☑ 611 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 51+354  T 405  ☑ 405 \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Q 97+752  T 849  ☑ 849 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 357+322 T 679  ☑ 679 \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Q 225+374 T 599  ☑ 599 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll get to 99+% validation accuracy after ~30 epochs."
      ],
      "metadata": {
        "id": "U_W3tycYOxwz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}