{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/My_Neural_Network_Architecture/blob/main/Image_classification_with_modern_MLP_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This example implements three modern attention-free, multi-layer perceptron (MLP) based models for image classification, demonstrated on the CIFAR-100 dataset:\n",
        "\n",
        "The MLP-Mixer model, by Ilya Tolstikhin et al., based on two types of MLPs.The FNet model, by James Lee-Thorp et al., based on unparameterized Fourier Transform.The gMLP model, by Hanxiao Liu et al., based on MLP with gating.\n",
        "The purpose of the example is not to compare between these models, as they might perform differently on different datasets with well-tuned hyperparameters. Rather, it is to show simple implementations of their main building blocks."
      ],
      "metadata": {
        "id": "BtF1ey0BiEaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27XFM-Mnm5M2",
        "outputId": "233ca704-bd14-475a-8e7b-34384d518c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6VyTz8zsakE",
        "outputId": "e618b484-a9fb-4240-9310-83ebb1861921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDz1F2EZs62x",
        "outputId": "03b1e975-b7b5-4aa8-a43c-b69f5aa72d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train),(x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyBZD_D9xLcS",
        "outputId": "6738c992-1371-4e45-b824-11ffa884a692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 64 X 64 = 4096\n",
            "Patch size: 8 X 8 = 64 \n",
            "Patches per image: 64\n",
            "Elements per patch (3 channels): 192\n"
          ]
        }
      ],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.2\n",
        "image_size = 64  # We'll resize input images to this size.\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images.\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
        "embedding_dim = 256  # Number of hidden units.\n",
        "num_blocks = 4  # Number of blocks.\n",
        "\n",
        "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a classification model\n",
        "\n",
        "We implement a method that builds a classifier given the processing blocks."
      ],
      "metadata": {
        "id": "VNhzSR8r0ra9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d-1ELpwxbmc"
      },
      "outputs": [],
      "source": [
        "def build_classifier(blocks, positional_encoding=False):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size, num_patches)(augmented)\n",
        "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
        "    x = layers.Dense(units=embedding_dim)(patches)\n",
        "    if positional_encoding:\n",
        "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "        position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=embedding_dim\n",
        "        )(positions)\n",
        "        x = x + position_embedding\n",
        "    # Process x using the module blocks.\n",
        "    x = blocks(x)\n",
        "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n",
        "    representation = layers.GlobalAveragePooling1D()(x)\n",
        "    # Apply dropout.\n",
        "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
        "    # Compute logits outputs.\n",
        "    logits = layers.Dense(num_classes)(representation)\n",
        "    # Create the Keras model.\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define an experiment\n",
        "\n",
        "We implement a utility function to compile, train, and evaluate a given model."
      ],
      "metadata": {
        "id": "QDMcN46y03u5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As9yy2iYyV5Y"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model):\n",
        "    # Create Adam optimizer with weight decay.\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
        "    )\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
        "        ],\n",
        "    )\n",
        "    # Create a learning rate scheduler callback.\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5\n",
        "    )\n",
        "    # Create an early stopping callback.\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
        "    )\n",
        "    # Fit the model.\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    # Return history to plot learning curves.\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0_rLUI9yfsa"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement patch extraction as a layer"
      ],
      "metadata": {
        "id": "u4LCq6k10-og"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1NRmkpazGNv"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, num_patches):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The MLP-Mixer model**\n",
        "\n",
        "The MLP-Mixer is an architecture based exclusively on multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
        "One applied independently to image patches, which mixes the per-location features.The other applied across patches (along channels), which mixes spatial information.\n",
        "This is similar to a depthwise separable convolution based model such as the Xception model, but with two chained dense transforms, no max pooling, and layer normalization instead of batch normalization."
      ],
      "metadata": {
        "id": "MTandfM81EiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs36XKjVzLmy"
      },
      "outputs": [],
      "source": [
        "class MLPMixerLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.mlp1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=num_patches),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.mlp2 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize(inputs)\n",
        "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
        "        x_channels = tf.linalg.matrix_transpose(x)\n",
        "        # Apply mlp1 on each channel independently.\n",
        "        mlp1_outputs = self.mlp1(x_channels)\n",
        "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
        "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
        "        # Add skip connection.\n",
        "        x = mlp1_outputs + inputs\n",
        "        # Apply layer normalization.\n",
        "        x_patches = self.normalize(x)\n",
        "        # Apply mlp2 on each patch independtenly.\n",
        "        mlp2_outputs = self.mlp2(x_patches)\n",
        "        # Add skip connection.\n",
        "        x = x + mlp2_outputs\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build, train, and evaluate the MLP-Mixer model**\n",
        "Note that training the model with the current settings on a V100 GPUs takes around 8 seconds per epoch."
      ],
      "metadata": {
        "id": "wec_yLH41_wG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pheXm1bXz6GZ",
        "outputId": "61df02bb-8832-42c9-c179-5e0001139b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 32s 56ms/step - loss: 3.8450 - acc: 0.1158 - top5-acc: 0.3254 - val_loss: 3.5781 - val_acc: 0.1692 - val_top5-acc: 0.4248 - lr: 0.0050\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 3.3554 - acc: 0.1948 - top5-acc: 0.4652 - val_loss: 3.2661 - val_acc: 0.2166 - val_top5-acc: 0.5028 - lr: 0.0050\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 3.1717 - acc: 0.2286 - top5-acc: 0.5158 - val_loss: 3.0820 - val_acc: 0.2514 - val_top5-acc: 0.5476 - lr: 0.0050\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 3.0203 - acc: 0.2589 - top5-acc: 0.5553 - val_loss: 2.8966 - val_acc: 0.2768 - val_top5-acc: 0.5852 - lr: 0.0050\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.9110 - acc: 0.2742 - top5-acc: 0.5802 - val_loss: 2.9063 - val_acc: 0.2884 - val_top5-acc: 0.5948 - lr: 0.0050\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.8277 - acc: 0.2923 - top5-acc: 0.6007 - val_loss: 2.8500 - val_acc: 0.2968 - val_top5-acc: 0.6088 - lr: 0.0050\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.7520 - acc: 0.3072 - top5-acc: 0.6192 - val_loss: 2.7679 - val_acc: 0.3192 - val_top5-acc: 0.6278 - lr: 0.0050\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.7055 - acc: 0.3155 - top5-acc: 0.6283 - val_loss: 2.7404 - val_acc: 0.3300 - val_top5-acc: 0.6316 - lr: 0.0050\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.6576 - acc: 0.3257 - top5-acc: 0.6415 - val_loss: 2.7405 - val_acc: 0.3256 - val_top5-acc: 0.6406 - lr: 0.0050\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.6282 - acc: 0.3323 - top5-acc: 0.6484 - val_loss: 2.6385 - val_acc: 0.3484 - val_top5-acc: 0.6582 - lr: 0.0050\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.5782 - acc: 0.3421 - top5-acc: 0.6598 - val_loss: 2.7494 - val_acc: 0.3314 - val_top5-acc: 0.6442 - lr: 0.0050\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.5450 - acc: 0.3499 - top5-acc: 0.6649 - val_loss: 2.6467 - val_acc: 0.3536 - val_top5-acc: 0.6672 - lr: 0.0050\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.5238 - acc: 0.3536 - top5-acc: 0.6728 - val_loss: 2.5660 - val_acc: 0.3624 - val_top5-acc: 0.6720 - lr: 0.0050\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.4916 - acc: 0.3606 - top5-acc: 0.6775 - val_loss: 2.5357 - val_acc: 0.3600 - val_top5-acc: 0.6776 - lr: 0.0050\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.4723 - acc: 0.3595 - top5-acc: 0.6815 - val_loss: 2.5520 - val_acc: 0.3676 - val_top5-acc: 0.6754 - lr: 0.0050\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 19s 55ms/step - loss: 2.4544 - acc: 0.3676 - top5-acc: 0.6845 - val_loss: 2.4601 - val_acc: 0.3822 - val_top5-acc: 0.6886 - lr: 0.0050\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.4218 - acc: 0.3727 - top5-acc: 0.6919 - val_loss: 2.4794 - val_acc: 0.3766 - val_top5-acc: 0.6916 - lr: 0.0050\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.3983 - acc: 0.3776 - top5-acc: 0.6988 - val_loss: 2.5132 - val_acc: 0.3792 - val_top5-acc: 0.6958 - lr: 0.0050\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.3710 - acc: 0.3819 - top5-acc: 0.7010 - val_loss: 2.4187 - val_acc: 0.3992 - val_top5-acc: 0.6990 - lr: 0.0050\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.3575 - acc: 0.3881 - top5-acc: 0.7034 - val_loss: 2.4138 - val_acc: 0.3872 - val_top5-acc: 0.7060 - lr: 0.0050\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.3262 - acc: 0.3934 - top5-acc: 0.7122 - val_loss: 2.4288 - val_acc: 0.3978 - val_top5-acc: 0.7090 - lr: 0.0050\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.3283 - acc: 0.3933 - top5-acc: 0.7114 - val_loss: 2.4336 - val_acc: 0.3874 - val_top5-acc: 0.7048 - lr: 0.0050\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.3052 - acc: 0.3967 - top5-acc: 0.7188 - val_loss: 2.4610 - val_acc: 0.3970 - val_top5-acc: 0.6986 - lr: 0.0050\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.2864 - acc: 0.3994 - top5-acc: 0.7200 - val_loss: 2.3895 - val_acc: 0.3978 - val_top5-acc: 0.7098 - lr: 0.0050\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.2733 - acc: 0.4046 - top5-acc: 0.7250 - val_loss: 2.3726 - val_acc: 0.3972 - val_top5-acc: 0.7158 - lr: 0.0050\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.2598 - acc: 0.4071 - top5-acc: 0.7248 - val_loss: 2.4116 - val_acc: 0.4010 - val_top5-acc: 0.7070 - lr: 0.0050\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.2489 - acc: 0.4074 - top5-acc: 0.7269 - val_loss: 2.2896 - val_acc: 0.4174 - val_top5-acc: 0.7344 - lr: 0.0050\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.2352 - acc: 0.4107 - top5-acc: 0.7325 - val_loss: 2.3066 - val_acc: 0.4154 - val_top5-acc: 0.7214 - lr: 0.0050\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.2302 - acc: 0.4131 - top5-acc: 0.7319 - val_loss: 2.3358 - val_acc: 0.4166 - val_top5-acc: 0.7202 - lr: 0.0050\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 18s 53ms/step - loss: 2.2133 - acc: 0.4165 - top5-acc: 0.7347 - val_loss: 2.3052 - val_acc: 0.4156 - val_top5-acc: 0.7302 - lr: 0.0050\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.1868 - acc: 0.4218 - top5-acc: 0.7417 - val_loss: 2.3168 - val_acc: 0.4196 - val_top5-acc: 0.7314 - lr: 0.0050\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1820 - acc: 0.4224 - top5-acc: 0.7405 - val_loss: 2.2611 - val_acc: 0.4310 - val_top5-acc: 0.7452 - lr: 0.0050\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1730 - acc: 0.4258 - top5-acc: 0.7433 - val_loss: 2.3727 - val_acc: 0.4002 - val_top5-acc: 0.7202 - lr: 0.0050\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.1663 - acc: 0.4221 - top5-acc: 0.7468 - val_loss: 2.2621 - val_acc: 0.4278 - val_top5-acc: 0.7384 - lr: 0.0050\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.1553 - acc: 0.4286 - top5-acc: 0.7461 - val_loss: 2.2979 - val_acc: 0.4214 - val_top5-acc: 0.7334 - lr: 0.0050\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.1553 - acc: 0.4289 - top5-acc: 0.7490 - val_loss: 2.2744 - val_acc: 0.4208 - val_top5-acc: 0.7386 - lr: 0.0050\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1368 - acc: 0.4323 - top5-acc: 0.7506 - val_loss: 2.2439 - val_acc: 0.4326 - val_top5-acc: 0.7400 - lr: 0.0050\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.1290 - acc: 0.4352 - top5-acc: 0.7500 - val_loss: 2.2788 - val_acc: 0.4200 - val_top5-acc: 0.7384 - lr: 0.0050\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1199 - acc: 0.4349 - top5-acc: 0.7546 - val_loss: 2.3110 - val_acc: 0.4222 - val_top5-acc: 0.7400 - lr: 0.0050\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.1197 - acc: 0.4361 - top5-acc: 0.7536 - val_loss: 2.2225 - val_acc: 0.4346 - val_top5-acc: 0.7400 - lr: 0.0050\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.1238 - acc: 0.4356 - top5-acc: 0.7529 - val_loss: 2.2284 - val_acc: 0.4342 - val_top5-acc: 0.7436 - lr: 0.0050\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.1099 - acc: 0.4395 - top5-acc: 0.7570 - val_loss: 2.2345 - val_acc: 0.4216 - val_top5-acc: 0.7418 - lr: 0.0050\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1046 - acc: 0.4395 - top5-acc: 0.7555 - val_loss: 2.2414 - val_acc: 0.4346 - val_top5-acc: 0.7510 - lr: 0.0050\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.0935 - acc: 0.4428 - top5-acc: 0.7607 - val_loss: 2.2844 - val_acc: 0.4344 - val_top5-acc: 0.7338 - lr: 0.0050\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.0881 - acc: 0.4430 - top5-acc: 0.7611 - val_loss: 2.2755 - val_acc: 0.4218 - val_top5-acc: 0.7454 - lr: 0.0050\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 1.8571 - acc: 0.4950 - top5-acc: 0.7999 - val_loss: 2.0722 - val_acc: 0.4638 - val_top5-acc: 0.7746 - lr: 0.0025\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8097 - acc: 0.5050 - top5-acc: 0.8097 - val_loss: 2.0145 - val_acc: 0.4776 - val_top5-acc: 0.7758 - lr: 0.0025\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 1.7899 - acc: 0.5106 - top5-acc: 0.8126 - val_loss: 2.1114 - val_acc: 0.4602 - val_top5-acc: 0.7648 - lr: 0.0025\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 1.7860 - acc: 0.5088 - top5-acc: 0.8134 - val_loss: 2.0183 - val_acc: 0.4798 - val_top5-acc: 0.7788 - lr: 0.0025\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 1.7732 - acc: 0.5128 - top5-acc: 0.8137 - val_loss: 2.0327 - val_acc: 0.4668 - val_top5-acc: 0.7768 - lr: 0.0025\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 1.9926 - acc: 0.4856 - top5-acc: 0.7784\n",
            "Test accuracy: 48.56%\n",
            "Test top 5 accuracy: 77.84%\n"
          ]
        }
      ],
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.005\n",
        "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
        "history = run_experiment(mlpmixer_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned in the MLP-Mixer paper, when pre-trained on large datasets, or with modern regularization schemes, the MLP-Mixer attains competitive scores to state-of-the-art models. You can obtain better results by increasing the embedding dimensions, increasing, increasing the number of mixer blocks, and training the model for longer. You may also try to increase the size of the input images and use different patch sizes."
      ],
      "metadata": {
        "id": "fHLMtSBk2p-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The FNet model**\n",
        "\n",
        "The FNet uses a similar block to the Transformer block. However, FNet replaces the self-attention layer in the Transformer block with a parameter-free 2D Fourier transformation layer:\n",
        "\n",
        "One 1D Fourier Transform is applied along the patches.One 1D Fourier Transform is applied along the channels."
      ],
      "metadata": {
        "id": "hOEZ5dKl2sM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FNetLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply fourier transformations.\n",
        "        x = tf.cast(\n",
        "            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n",
        "            dtype=tf.dtypes.float32,\n",
        "        )\n",
        "        # Add skip connection.\n",
        "        x = x + inputs\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize1(x)\n",
        "        # Apply Feedfowrad network.\n",
        "        x_ffn = self.ffn(x)\n",
        "        # Add skip connection.\n",
        "        x = x + x_ffn\n",
        "        # Apply layer normalization.\n",
        "        return self.normalize2(x)"
      ],
      "metadata": {
        "id": "EXdTS3g5jchT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnet_blocks = keras.Sequential(\n",
        "    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.001\n",
        "fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n",
        "history = run_experiment(fnet_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0KfQDJEjo-A",
        "outputId": "3af861b1-ddc6-4de6-d3c0-56b14e825853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "351/352 [============================>.] - ETA: 0s - loss: 4.1219 - acc: 0.0741 - top5-acc: 0.2318"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r352/352 [==============================] - 23s 55ms/step - loss: 4.1213 - acc: 0.0741 - top5-acc: 0.2320 - val_loss: 3.7878 - val_acc: 0.1236 - val_top5-acc: 0.3350 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 3.6992 - acc: 0.1326 - top5-acc: 0.3584 - val_loss: 3.5338 - val_acc: 0.1690 - val_top5-acc: 0.4090 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 3.4470 - acc: 0.1728 - top5-acc: 0.4350 - val_loss: 3.2606 - val_acc: 0.2110 - val_top5-acc: 0.4822 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 3.2351 - acc: 0.2098 - top5-acc: 0.4933 - val_loss: 3.1649 - val_acc: 0.2282 - val_top5-acc: 0.5036 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 3.0950 - acc: 0.2359 - top5-acc: 0.5294 - val_loss: 2.9656 - val_acc: 0.2624 - val_top5-acc: 0.5660 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.9770 - acc: 0.2568 - top5-acc: 0.5592 - val_loss: 2.9039 - val_acc: 0.2736 - val_top5-acc: 0.5698 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.8912 - acc: 0.2749 - top5-acc: 0.5808 - val_loss: 2.7747 - val_acc: 0.2982 - val_top5-acc: 0.6006 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 2.8051 - acc: 0.2906 - top5-acc: 0.6013 - val_loss: 2.7521 - val_acc: 0.3030 - val_top5-acc: 0.6182 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.7449 - acc: 0.3043 - top5-acc: 0.6151 - val_loss: 2.6465 - val_acc: 0.3256 - val_top5-acc: 0.6424 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.6795 - acc: 0.3167 - top5-acc: 0.6296 - val_loss: 2.6048 - val_acc: 0.3334 - val_top5-acc: 0.6536 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 19s 55ms/step - loss: 2.6311 - acc: 0.3267 - top5-acc: 0.6407 - val_loss: 2.6289 - val_acc: 0.3280 - val_top5-acc: 0.6496 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 19s 55ms/step - loss: 2.5811 - acc: 0.3377 - top5-acc: 0.6525 - val_loss: 2.5632 - val_acc: 0.3436 - val_top5-acc: 0.6516 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.5263 - acc: 0.3494 - top5-acc: 0.6656 - val_loss: 2.5312 - val_acc: 0.3500 - val_top5-acc: 0.6678 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.4895 - acc: 0.3555 - top5-acc: 0.6753 - val_loss: 2.4607 - val_acc: 0.3568 - val_top5-acc: 0.6760 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.4502 - acc: 0.3637 - top5-acc: 0.6822 - val_loss: 2.4614 - val_acc: 0.3702 - val_top5-acc: 0.6768 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.4159 - acc: 0.3686 - top5-acc: 0.6890 - val_loss: 2.4209 - val_acc: 0.3756 - val_top5-acc: 0.6792 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.3798 - acc: 0.3785 - top5-acc: 0.6959 - val_loss: 2.4046 - val_acc: 0.3788 - val_top5-acc: 0.6938 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.3439 - acc: 0.3860 - top5-acc: 0.7073 - val_loss: 2.3732 - val_acc: 0.3888 - val_top5-acc: 0.6940 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.3262 - acc: 0.3891 - top5-acc: 0.7079 - val_loss: 2.4220 - val_acc: 0.3750 - val_top5-acc: 0.6868 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.2840 - acc: 0.3985 - top5-acc: 0.7178 - val_loss: 2.3247 - val_acc: 0.3982 - val_top5-acc: 0.7076 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.2649 - acc: 0.4026 - top5-acc: 0.7218 - val_loss: 2.3111 - val_acc: 0.3944 - val_top5-acc: 0.7156 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.2354 - acc: 0.4098 - top5-acc: 0.7274 - val_loss: 2.3158 - val_acc: 0.3916 - val_top5-acc: 0.7112 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.2152 - acc: 0.4136 - top5-acc: 0.7306 - val_loss: 2.2937 - val_acc: 0.4036 - val_top5-acc: 0.7144 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 19s 55ms/step - loss: 2.1970 - acc: 0.4161 - top5-acc: 0.7378 - val_loss: 2.2641 - val_acc: 0.3962 - val_top5-acc: 0.7266 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.1791 - acc: 0.4233 - top5-acc: 0.7407 - val_loss: 2.2711 - val_acc: 0.4098 - val_top5-acc: 0.7162 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 19s 55ms/step - loss: 2.1636 - acc: 0.4268 - top5-acc: 0.7436 - val_loss: 2.2479 - val_acc: 0.4132 - val_top5-acc: 0.7234 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.1383 - acc: 0.4311 - top5-acc: 0.7485 - val_loss: 2.2395 - val_acc: 0.4170 - val_top5-acc: 0.7212 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.1322 - acc: 0.4327 - top5-acc: 0.7512 - val_loss: 2.2469 - val_acc: 0.4076 - val_top5-acc: 0.7262 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.1091 - acc: 0.4363 - top5-acc: 0.7538 - val_loss: 2.2203 - val_acc: 0.4134 - val_top5-acc: 0.7286 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.0971 - acc: 0.4381 - top5-acc: 0.7579 - val_loss: 2.2017 - val_acc: 0.4164 - val_top5-acc: 0.7294 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.0863 - acc: 0.4424 - top5-acc: 0.7571 - val_loss: 2.1895 - val_acc: 0.4228 - val_top5-acc: 0.7402 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.0633 - acc: 0.4459 - top5-acc: 0.7642 - val_loss: 2.1662 - val_acc: 0.4276 - val_top5-acc: 0.7356 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.0619 - acc: 0.4488 - top5-acc: 0.7636 - val_loss: 2.1414 - val_acc: 0.4336 - val_top5-acc: 0.7402 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 2.0478 - acc: 0.4516 - top5-acc: 0.7672 - val_loss: 2.1904 - val_acc: 0.4322 - val_top5-acc: 0.7352 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 18s 52ms/step - loss: 2.0294 - acc: 0.4557 - top5-acc: 0.7707 - val_loss: 2.1758 - val_acc: 0.4326 - val_top5-acc: 0.7394 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.0213 - acc: 0.4582 - top5-acc: 0.7728 - val_loss: 2.1678 - val_acc: 0.4272 - val_top5-acc: 0.7404 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 2.0206 - acc: 0.4566 - top5-acc: 0.7707 - val_loss: 2.2104 - val_acc: 0.4284 - val_top5-acc: 0.7378 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 1.9951 - acc: 0.4645 - top5-acc: 0.7754 - val_loss: 2.1881 - val_acc: 0.4302 - val_top5-acc: 0.7426 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8736 - acc: 0.4902 - top5-acc: 0.7998 - val_loss: 2.0436 - val_acc: 0.4556 - val_top5-acc: 0.7696 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 1.8491 - acc: 0.4985 - top5-acc: 0.8060 - val_loss: 2.0573 - val_acc: 0.4524 - val_top5-acc: 0.7658 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 18s 51ms/step - loss: 1.8436 - acc: 0.4990 - top5-acc: 0.8066 - val_loss: 2.0677 - val_acc: 0.4522 - val_top5-acc: 0.7618 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8500 - acc: 0.4958 - top5-acc: 0.8060 - val_loss: 2.0586 - val_acc: 0.4586 - val_top5-acc: 0.7618 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8480 - acc: 0.4987 - top5-acc: 0.8053 - val_loss: 2.0667 - val_acc: 0.4476 - val_top5-acc: 0.7620 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8488 - acc: 0.4945 - top5-acc: 0.8058 - val_loss: 2.0456 - val_acc: 0.4592 - val_top5-acc: 0.7648 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.7811 - acc: 0.5162 - top5-acc: 0.8197 - val_loss: 2.0261 - val_acc: 0.4646 - val_top5-acc: 0.7662 - lr: 2.5000e-04\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.7910 - acc: 0.5154 - top5-acc: 0.8183 - val_loss: 2.0077 - val_acc: 0.4688 - val_top5-acc: 0.7708 - lr: 2.5000e-04\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 19s 54ms/step - loss: 1.8050 - acc: 0.5122 - top5-acc: 0.8152 - val_loss: 2.0139 - val_acc: 0.4646 - val_top5-acc: 0.7726 - lr: 2.5000e-04\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8297 - acc: 0.5078 - top5-acc: 0.8103 - val_loss: 2.0094 - val_acc: 0.4628 - val_top5-acc: 0.7740 - lr: 2.5000e-04\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8396 - acc: 0.5021 - top5-acc: 0.8114 - val_loss: 2.0453 - val_acc: 0.4566 - val_top5-acc: 0.7658 - lr: 2.5000e-04\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 19s 53ms/step - loss: 1.8503 - acc: 0.5010 - top5-acc: 0.8083 - val_loss: 2.0301 - val_acc: 0.4604 - val_top5-acc: 0.7674 - lr: 2.5000e-04\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.0000 - acc: 0.4707 - top5-acc: 0.7715\n",
            "Test accuracy: 47.07%\n",
            "Test top 5 accuracy: 77.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the FNet paper, better results can be achieved by increasing the embedding dimensions, increasing the number of FNet blocks, and training the model for longer. You may also try to increase the size of the input images and use different patch sizes. The FNet scales very efficiently to long inputs, runs much faster than attention-based Transformer models, and produces competitive accuracy results."
      ],
      "metadata": {
        "id": "hp3rr5Tv3Cp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The gMLP model***\n",
        "\n",
        "The gMLP is a MLP architecture that features a Spatial Gating Unit (SGU). The SGU enables cross-patch interactions across the spatial (channel) dimension, by:\n",
        "\n",
        "Transforming the input spatially by applying linear projection across patches (along channels).Applying element-wise multiplication of the input and its spatial transformation."
      ],
      "metadata": {
        "id": "Io-cdr2F3FFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class gMLPLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channel_projection1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embedding_dim * 2),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.channel_projection2 = layers.Dense(units=embedding_dim)\n",
        "\n",
        "        self.spatial_projection = layers.Dense(\n",
        "            units=num_patches, bias_initializer=\"Ones\"\n",
        "        )\n",
        "\n",
        "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def spatial_gating_unit(self, x):\n",
        "        # Split x along the channel dimensions.\n",
        "        # Tensors u and v will in th shape of [batch_size, num_patchs, embedding_dim].\n",
        "        u, v = tf.split(x, num_or_size_splits=2, axis=2)\n",
        "        # Apply layer normalization.\n",
        "        v = self.normalize2(v)\n",
        "        # Apply spatial projection.\n",
        "        v_channels = tf.linalg.matrix_transpose(v)\n",
        "        v_projected = self.spatial_projection(v_channels)\n",
        "        v_projected = tf.linalg.matrix_transpose(v_projected)\n",
        "        # Apply element-wise multiplication.\n",
        "        return u * v_projected\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize1(inputs)\n",
        "        # Apply the first channel projection. x_projected shape: [batch_size, num_patches, embedding_dim * 2].\n",
        "        x_projected = self.channel_projection1(x)\n",
        "        # Apply the spatial gating unit. x_spatial shape: [batch_size, num_patches, embedding_dim].\n",
        "        x_spatial = self.spatial_gating_unit(x_projected)\n",
        "        # Apply the second channel projection. x_projected shape: [batch_size, num_patches, embedding_dim].\n",
        "        x_projected = self.channel_projection2(x_spatial)\n",
        "        # Add skip connection.\n",
        "        return x + x_projected"
      ],
      "metadata": {
        "id": "kVFqUrFHjtA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmlp_blocks = keras.Sequential(\n",
        "    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.003\n",
        "gmlp_classifier = build_classifier(gmlp_blocks)\n",
        "history = run_experiment(gmlp_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVtfHed1ktOG",
        "outputId": "4bbb2733-b179-4dfa-f277-9a99cf17df05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/352 [==============================] - 29s 67ms/step - loss: 3.9044 - acc: 0.1028 - top5-acc: 0.2972 - val_loss: 3.5036 - val_acc: 0.1686 - val_top5-acc: 0.4248 - lr: 0.0030\n",
            "Epoch 2/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 3.4538 - acc: 0.1708 - top5-acc: 0.4348 - val_loss: 3.2793 - val_acc: 0.2044 - val_top5-acc: 0.4830 - lr: 0.0030\n",
            "Epoch 3/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 3.2154 - acc: 0.2135 - top5-acc: 0.5004 - val_loss: 3.1017 - val_acc: 0.2398 - val_top5-acc: 0.5378 - lr: 0.0030\n",
            "Epoch 4/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 3.0340 - acc: 0.2486 - top5-acc: 0.5460 - val_loss: 2.8825 - val_acc: 0.2718 - val_top5-acc: 0.5900 - lr: 0.0030\n",
            "Epoch 5/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 2.9018 - acc: 0.2763 - top5-acc: 0.5775 - val_loss: 2.8247 - val_acc: 0.2944 - val_top5-acc: 0.6022 - lr: 0.0030\n",
            "Epoch 6/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.7935 - acc: 0.2977 - top5-acc: 0.6050 - val_loss: 2.7107 - val_acc: 0.3192 - val_top5-acc: 0.6332 - lr: 0.0030\n",
            "Epoch 7/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.6948 - acc: 0.3134 - top5-acc: 0.6297 - val_loss: 2.6378 - val_acc: 0.3378 - val_top5-acc: 0.6456 - lr: 0.0030\n",
            "Epoch 8/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.6185 - acc: 0.3333 - top5-acc: 0.6448 - val_loss: 2.5376 - val_acc: 0.3604 - val_top5-acc: 0.6654 - lr: 0.0030\n",
            "Epoch 9/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.5510 - acc: 0.3463 - top5-acc: 0.6620 - val_loss: 2.5018 - val_acc: 0.3622 - val_top5-acc: 0.6760 - lr: 0.0030\n",
            "Epoch 10/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.4883 - acc: 0.3596 - top5-acc: 0.6758 - val_loss: 2.4970 - val_acc: 0.3696 - val_top5-acc: 0.6770 - lr: 0.0030\n",
            "Epoch 11/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.4215 - acc: 0.3724 - top5-acc: 0.6874 - val_loss: 2.4131 - val_acc: 0.3826 - val_top5-acc: 0.6998 - lr: 0.0030\n",
            "Epoch 12/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 2.3730 - acc: 0.3807 - top5-acc: 0.6990 - val_loss: 2.4111 - val_acc: 0.3840 - val_top5-acc: 0.7004 - lr: 0.0030\n",
            "Epoch 13/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.3353 - acc: 0.3896 - top5-acc: 0.7078 - val_loss: 2.3803 - val_acc: 0.3940 - val_top5-acc: 0.7020 - lr: 0.0030\n",
            "Epoch 14/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.2952 - acc: 0.3982 - top5-acc: 0.7146 - val_loss: 2.3498 - val_acc: 0.3942 - val_top5-acc: 0.7118 - lr: 0.0030\n",
            "Epoch 15/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 2.2629 - acc: 0.4081 - top5-acc: 0.7221 - val_loss: 2.3513 - val_acc: 0.4036 - val_top5-acc: 0.7092 - lr: 0.0030\n",
            "Epoch 16/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 2.2278 - acc: 0.4114 - top5-acc: 0.7308 - val_loss: 2.3615 - val_acc: 0.3992 - val_top5-acc: 0.7120 - lr: 0.0030\n",
            "Epoch 17/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 2.2026 - acc: 0.4207 - top5-acc: 0.7340 - val_loss: 2.2915 - val_acc: 0.4152 - val_top5-acc: 0.7264 - lr: 0.0030\n",
            "Epoch 18/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 2.1896 - acc: 0.4185 - top5-acc: 0.7373 - val_loss: 2.2582 - val_acc: 0.4242 - val_top5-acc: 0.7256 - lr: 0.0030\n",
            "Epoch 19/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.1572 - acc: 0.4266 - top5-acc: 0.7440 - val_loss: 2.2645 - val_acc: 0.4184 - val_top5-acc: 0.7296 - lr: 0.0030\n",
            "Epoch 20/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.1408 - acc: 0.4302 - top5-acc: 0.7473 - val_loss: 2.2420 - val_acc: 0.4264 - val_top5-acc: 0.7278 - lr: 0.0030\n",
            "Epoch 21/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.1186 - acc: 0.4358 - top5-acc: 0.7534 - val_loss: 2.2408 - val_acc: 0.4244 - val_top5-acc: 0.7284 - lr: 0.0030\n",
            "Epoch 22/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.0940 - acc: 0.4420 - top5-acc: 0.7585 - val_loss: 2.2488 - val_acc: 0.4250 - val_top5-acc: 0.7330 - lr: 0.0030\n",
            "Epoch 23/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.0800 - acc: 0.4428 - top5-acc: 0.7580 - val_loss: 2.2731 - val_acc: 0.4204 - val_top5-acc: 0.7292 - lr: 0.0030\n",
            "Epoch 24/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.0645 - acc: 0.4506 - top5-acc: 0.7645 - val_loss: 2.2875 - val_acc: 0.4256 - val_top5-acc: 0.7270 - lr: 0.0030\n",
            "Epoch 25/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 2.0555 - acc: 0.4496 - top5-acc: 0.7655 - val_loss: 2.2343 - val_acc: 0.4270 - val_top5-acc: 0.7350 - lr: 0.0030\n",
            "Epoch 26/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 2.0372 - acc: 0.4525 - top5-acc: 0.7665 - val_loss: 2.1824 - val_acc: 0.4426 - val_top5-acc: 0.7384 - lr: 0.0030\n",
            "Epoch 27/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 2.0151 - acc: 0.4584 - top5-acc: 0.7700 - val_loss: 2.2082 - val_acc: 0.4456 - val_top5-acc: 0.7478 - lr: 0.0030\n",
            "Epoch 28/50\n",
            "352/352 [==============================] - 22s 64ms/step - loss: 2.0003 - acc: 0.4628 - top5-acc: 0.7736 - val_loss: 2.2488 - val_acc: 0.4410 - val_top5-acc: 0.7348 - lr: 0.0030\n",
            "Epoch 29/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.9811 - acc: 0.4668 - top5-acc: 0.7774 - val_loss: 2.2244 - val_acc: 0.4360 - val_top5-acc: 0.7470 - lr: 0.0030\n",
            "Epoch 30/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 1.9601 - acc: 0.4699 - top5-acc: 0.7844 - val_loss: 2.2643 - val_acc: 0.4320 - val_top5-acc: 0.7338 - lr: 0.0030\n",
            "Epoch 31/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.9437 - acc: 0.4754 - top5-acc: 0.7854 - val_loss: 2.1557 - val_acc: 0.4506 - val_top5-acc: 0.7540 - lr: 0.0030\n",
            "Epoch 32/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.9232 - acc: 0.4809 - top5-acc: 0.7903 - val_loss: 2.2222 - val_acc: 0.4444 - val_top5-acc: 0.7422 - lr: 0.0030\n",
            "Epoch 33/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.9047 - acc: 0.4835 - top5-acc: 0.7933 - val_loss: 2.1962 - val_acc: 0.4442 - val_top5-acc: 0.7500 - lr: 0.0030\n",
            "Epoch 34/50\n",
            "352/352 [==============================] - 22s 64ms/step - loss: 1.9013 - acc: 0.4841 - top5-acc: 0.7940 - val_loss: 2.1643 - val_acc: 0.4514 - val_top5-acc: 0.7448 - lr: 0.0030\n",
            "Epoch 35/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.8851 - acc: 0.4861 - top5-acc: 0.7983 - val_loss: 2.1859 - val_acc: 0.4422 - val_top5-acc: 0.7588 - lr: 0.0030\n",
            "Epoch 36/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.8749 - acc: 0.4860 - top5-acc: 0.8003 - val_loss: 2.1720 - val_acc: 0.4544 - val_top5-acc: 0.7514 - lr: 0.0030\n",
            "Epoch 37/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.6853 - acc: 0.5326 - top5-acc: 0.8300 - val_loss: 2.1275 - val_acc: 0.4708 - val_top5-acc: 0.7700 - lr: 0.0015\n",
            "Epoch 38/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.6374 - acc: 0.5464 - top5-acc: 0.8404 - val_loss: 2.1275 - val_acc: 0.4728 - val_top5-acc: 0.7690 - lr: 0.0015\n",
            "Epoch 39/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.6122 - acc: 0.5504 - top5-acc: 0.8441 - val_loss: 2.0931 - val_acc: 0.4790 - val_top5-acc: 0.7738 - lr: 0.0015\n",
            "Epoch 40/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.5916 - acc: 0.5551 - top5-acc: 0.8481 - val_loss: 2.1659 - val_acc: 0.4774 - val_top5-acc: 0.7666 - lr: 0.0015\n",
            "Epoch 41/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 1.5930 - acc: 0.5560 - top5-acc: 0.8470 - val_loss: 2.1067 - val_acc: 0.4812 - val_top5-acc: 0.7782 - lr: 0.0015\n",
            "Epoch 42/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.5820 - acc: 0.5560 - top5-acc: 0.8508 - val_loss: 2.1399 - val_acc: 0.4806 - val_top5-acc: 0.7730 - lr: 0.0015\n",
            "Epoch 43/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 1.5645 - acc: 0.5610 - top5-acc: 0.8527 - val_loss: 2.1045 - val_acc: 0.4814 - val_top5-acc: 0.7764 - lr: 0.0015\n",
            "Epoch 44/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.5546 - acc: 0.5656 - top5-acc: 0.8556 - val_loss: 2.1449 - val_acc: 0.4798 - val_top5-acc: 0.7722 - lr: 0.0015\n",
            "Epoch 45/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.4301 - acc: 0.5952 - top5-acc: 0.8749 - val_loss: 2.0637 - val_acc: 0.4998 - val_top5-acc: 0.7838 - lr: 7.5000e-04\n",
            "Epoch 46/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.3885 - acc: 0.6044 - top5-acc: 0.8791 - val_loss: 2.0841 - val_acc: 0.5004 - val_top5-acc: 0.7860 - lr: 7.5000e-04\n",
            "Epoch 47/50\n",
            "352/352 [==============================] - 23s 64ms/step - loss: 1.3853 - acc: 0.6066 - top5-acc: 0.8812 - val_loss: 2.0891 - val_acc: 0.4978 - val_top5-acc: 0.7808 - lr: 7.5000e-04\n",
            "Epoch 48/50\n",
            "352/352 [==============================] - 23s 66ms/step - loss: 1.3657 - acc: 0.6136 - top5-acc: 0.8840 - val_loss: 2.1252 - val_acc: 0.4958 - val_top5-acc: 0.7822 - lr: 7.5000e-04\n",
            "Epoch 49/50\n",
            "352/352 [==============================] - 25s 71ms/step - loss: 1.3496 - acc: 0.6152 - top5-acc: 0.8860 - val_loss: 2.1237 - val_acc: 0.4956 - val_top5-acc: 0.7782 - lr: 7.5000e-04\n",
            "Epoch 50/50\n",
            "352/352 [==============================] - 23s 65ms/step - loss: 1.3484 - acc: 0.6141 - top5-acc: 0.8894 - val_loss: 2.1016 - val_acc: 0.4970 - val_top5-acc: 0.7830 - lr: 7.5000e-04\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 2.0486 - acc: 0.5048 - top5-acc: 0.7886\n",
            "Test accuracy: 50.48%\n",
            "Test top 5 accuracy: 78.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the gMLP paper, better results can be achieved by increasing the embedding dimensions, increasing the number of gMLP blocks, and training the model for longer. You may also try to increase the size of the input images and use different patch sizes. Note that, the paper used advanced regularization strategies, such as MixUp and CutMix, as well as AutoAugment."
      ],
      "metadata": {
        "id": "BhbsitdA2kbT"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNr7wcViIl6phnrR6MfkqaH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}