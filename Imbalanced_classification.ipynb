{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/My_Neural_Network_Architecture/blob/main/Imbalanced_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Imbalanced classification: credit card fraud detection**"
      ],
      "metadata": {
        "id": "-vr5s-kFuw6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ],
      "metadata": {
        "id": "Uy3jmcxMEvF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"keggal_username\"\n",
        "os.environ['KAGGLE_KEY'] = \"keggal_user_keys\"\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "#os path\n",
        "api.dataset_download_files( \"mlg-ulb/creditcardfraud\",path=\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")\n",
        "# unzip"
      ],
      "metadata": {
        "id": "O2Z1iqDo13uU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/https:/www.kaggle.com/datasets/mlg-ulb/creditcardfraud/creditcardfraud.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4FcSvLp2Lt8",
        "outputId": "a5fad80d-37c0-45d1-a5c7-4799569e7f07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/https:/www.kaggle.com/datasets/mlg-ulb/creditcardfraud/creditcardfraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First, vectorize the CSV data"
      ],
      "metadata": {
        "id": "x2RqDSXHE1aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "fname = \"creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTnd62Nsuwa_",
        "outputId": "742dff34-d5c1-4095-ae99-8416fd28fb8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[: -num_val_samples]\n",
        "train_targets = targets[: -num_val_samples]\n",
        "\n",
        "val_features = features[-num_val_samples :]\n",
        "val_targets = targets[-num_val_samples :]\n",
        "\n",
        "print(\"length of training features is :::\", len(train_features))\n",
        "print(\"length of validation features is :::\", len(val_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRJQbQEd2YPe",
        "outputId": "9cfeb420-6107-4782-a4c5-790f26abb19e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training features is ::: 227846\n",
            "length of validation features is ::: 56961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze class imbalance in the targets"
      ],
      "metadata": {
        "id": "dupgbGqNE_ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuF1-S994AG2",
        "outputId": "a2e1676f-1936-4240-9db5-b442b15bf79e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize the data using training set statistics"
      ],
      "metadata": {
        "id": "JxYdGQ38FEcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(train_features, axis = 0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "\n",
        "std = np.std(train_features, axis = 0)\n",
        "train_features /= std\n",
        "val_features /= std"
      ],
      "metadata": {
        "id": "IzgjCbGf4POU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = train_features.shape[1:]),\n",
        "        keras.layers.Dense(256, activation = \"relu\"),\n",
        "        keras.layers.Dense(256, activation = \"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation = \"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation = \"sigmoid\")\n",
        "    ])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoYzLtOK6sNb",
        "outputId": "d9ee51ec-8429-44fb-a14e-00d6a1345412"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               7936      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139777 (546.00 KB)\n",
            "Trainable params: 139777 (546.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model with `class_weight` argument"
      ],
      "metadata": {
        "id": "DGVf3eDaFKbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROr8SWhPDTdn",
        "outputId": "8db4d68d-541d-42cc-aac6-0b70177ea558"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 9s - loss: 2.4156e-06 - fn: 45.0000 - fp: 28388.0000 - tn: 199041.0000 - tp: 372.0000 - precision: 0.0129 - recall: 0.8921 - val_loss: 0.0658 - val_fn: 11.0000 - val_fp: 391.0000 - val_tn: 56495.0000 - val_tp: 64.0000 - val_precision: 0.1407 - val_recall: 0.8533 - 9s/epoch - 76ms/step\n",
            "Epoch 2/30\n",
            "112/112 - 6s - loss: 1.4854e-06 - fn: 38.0000 - fp: 7192.0000 - tn: 220237.0000 - tp: 379.0000 - precision: 0.0501 - recall: 0.9089 - val_loss: 0.1383 - val_fn: 6.0000 - val_fp: 1847.0000 - val_tn: 55039.0000 - val_tp: 69.0000 - val_precision: 0.0360 - val_recall: 0.9200 - 6s/epoch - 56ms/step\n",
            "Epoch 3/30\n",
            "112/112 - 6s - loss: 1.2658e-06 - fn: 28.0000 - fp: 6952.0000 - tn: 220477.0000 - tp: 389.0000 - precision: 0.0530 - recall: 0.9329 - val_loss: 0.0877 - val_fn: 9.0000 - val_fp: 1153.0000 - val_tn: 55733.0000 - val_tp: 66.0000 - val_precision: 0.0541 - val_recall: 0.8800 - 6s/epoch - 51ms/step\n",
            "Epoch 4/30\n",
            "112/112 - 6s - loss: 1.0451e-06 - fn: 24.0000 - fp: 6970.0000 - tn: 220459.0000 - tp: 393.0000 - precision: 0.0534 - recall: 0.9424 - val_loss: 0.0706 - val_fn: 8.0000 - val_fp: 1335.0000 - val_tn: 55551.0000 - val_tp: 67.0000 - val_precision: 0.0478 - val_recall: 0.8933 - 6s/epoch - 50ms/step\n",
            "Epoch 5/30\n",
            "112/112 - 7s - loss: 9.1107e-07 - fn: 20.0000 - fp: 6449.0000 - tn: 220980.0000 - tp: 397.0000 - precision: 0.0580 - recall: 0.9520 - val_loss: 0.0618 - val_fn: 8.0000 - val_fp: 920.0000 - val_tn: 55966.0000 - val_tp: 67.0000 - val_precision: 0.0679 - val_recall: 0.8933 - 7s/epoch - 63ms/step\n",
            "Epoch 6/30\n",
            "112/112 - 5s - loss: 7.5929e-07 - fn: 18.0000 - fp: 6345.0000 - tn: 221084.0000 - tp: 399.0000 - precision: 0.0592 - recall: 0.9568 - val_loss: 0.0344 - val_fn: 9.0000 - val_fp: 514.0000 - val_tn: 56372.0000 - val_tp: 66.0000 - val_precision: 0.1138 - val_recall: 0.8800 - 5s/epoch - 47ms/step\n",
            "Epoch 7/30\n",
            "112/112 - 7s - loss: 7.2205e-07 - fn: 17.0000 - fp: 6685.0000 - tn: 220744.0000 - tp: 400.0000 - precision: 0.0565 - recall: 0.9592 - val_loss: 0.0237 - val_fn: 10.0000 - val_fp: 421.0000 - val_tn: 56465.0000 - val_tp: 65.0000 - val_precision: 0.1337 - val_recall: 0.8667 - 7s/epoch - 61ms/step\n",
            "Epoch 8/30\n",
            "112/112 - 5s - loss: 6.9422e-07 - fn: 13.0000 - fp: 6378.0000 - tn: 221051.0000 - tp: 404.0000 - precision: 0.0596 - recall: 0.9688 - val_loss: 0.0529 - val_fn: 6.0000 - val_fp: 1102.0000 - val_tn: 55784.0000 - val_tp: 69.0000 - val_precision: 0.0589 - val_recall: 0.9200 - 5s/epoch - 47ms/step\n",
            "Epoch 9/30\n",
            "112/112 - 7s - loss: 7.5113e-07 - fn: 17.0000 - fp: 8374.0000 - tn: 219055.0000 - tp: 400.0000 - precision: 0.0456 - recall: 0.9592 - val_loss: 0.0427 - val_fn: 9.0000 - val_fp: 716.0000 - val_tn: 56170.0000 - val_tp: 66.0000 - val_precision: 0.0844 - val_recall: 0.8800 - 7s/epoch - 61ms/step\n",
            "Epoch 10/30\n",
            "112/112 - 5s - loss: 7.3755e-07 - fn: 16.0000 - fp: 7238.0000 - tn: 220191.0000 - tp: 401.0000 - precision: 0.0525 - recall: 0.9616 - val_loss: 0.0170 - val_fn: 11.0000 - val_fp: 322.0000 - val_tn: 56564.0000 - val_tp: 64.0000 - val_precision: 0.1658 - val_recall: 0.8533 - 5s/epoch - 47ms/step\n",
            "Epoch 11/30\n",
            "112/112 - 6s - loss: 6.7405e-07 - fn: 14.0000 - fp: 7852.0000 - tn: 219577.0000 - tp: 403.0000 - precision: 0.0488 - recall: 0.9664 - val_loss: 0.0585 - val_fn: 9.0000 - val_fp: 1304.0000 - val_tn: 55582.0000 - val_tp: 66.0000 - val_precision: 0.0482 - val_recall: 0.8800 - 6s/epoch - 51ms/step\n",
            "Epoch 12/30\n",
            "112/112 - 7s - loss: 3.8527e-07 - fn: 4.0000 - fp: 4471.0000 - tn: 222958.0000 - tp: 413.0000 - precision: 0.0846 - recall: 0.9904 - val_loss: 0.0165 - val_fn: 10.0000 - val_fp: 355.0000 - val_tn: 56531.0000 - val_tp: 65.0000 - val_precision: 0.1548 - val_recall: 0.8667 - 7s/epoch - 59ms/step\n",
            "Epoch 13/30\n",
            "112/112 - 6s - loss: 4.2781e-07 - fn: 5.0000 - fp: 5251.0000 - tn: 222178.0000 - tp: 412.0000 - precision: 0.0728 - recall: 0.9880 - val_loss: 0.0651 - val_fn: 7.0000 - val_fp: 1740.0000 - val_tn: 55146.0000 - val_tp: 68.0000 - val_precision: 0.0376 - val_recall: 0.9067 - 6s/epoch - 56ms/step\n",
            "Epoch 14/30\n",
            "112/112 - 7s - loss: 2.3497e-06 - fn: 17.0000 - fp: 9022.0000 - tn: 218407.0000 - tp: 400.0000 - precision: 0.0425 - recall: 0.9592 - val_loss: 0.8746 - val_fn: 11.0000 - val_fp: 1260.0000 - val_tn: 55626.0000 - val_tp: 64.0000 - val_precision: 0.0483 - val_recall: 0.8533 - 7s/epoch - 62ms/step\n",
            "Epoch 15/30\n",
            "112/112 - 6s - loss: 3.3580e-06 - fn: 32.0000 - fp: 11012.0000 - tn: 216417.0000 - tp: 385.0000 - precision: 0.0338 - recall: 0.9233 - val_loss: 0.2303 - val_fn: 12.0000 - val_fp: 599.0000 - val_tn: 56287.0000 - val_tp: 63.0000 - val_precision: 0.0952 - val_recall: 0.8400 - 6s/epoch - 50ms/step\n",
            "Epoch 16/30\n",
            "112/112 - 7s - loss: 4.1407e-06 - fn: 27.0000 - fp: 6017.0000 - tn: 221412.0000 - tp: 390.0000 - precision: 0.0609 - recall: 0.9353 - val_loss: 0.2275 - val_fn: 6.0000 - val_fp: 2996.0000 - val_tn: 53890.0000 - val_tp: 69.0000 - val_precision: 0.0225 - val_recall: 0.9200 - 7s/epoch - 63ms/step\n",
            "Epoch 17/30\n",
            "112/112 - 6s - loss: 3.1084e-06 - fn: 26.0000 - fp: 8839.0000 - tn: 218590.0000 - tp: 391.0000 - precision: 0.0424 - recall: 0.9376 - val_loss: 0.0622 - val_fn: 8.0000 - val_fp: 450.0000 - val_tn: 56436.0000 - val_tp: 67.0000 - val_precision: 0.1296 - val_recall: 0.8933 - 6s/epoch - 50ms/step\n",
            "Epoch 18/30\n",
            "112/112 - 7s - loss: 2.6493e-06 - fn: 19.0000 - fp: 6170.0000 - tn: 221259.0000 - tp: 398.0000 - precision: 0.0606 - recall: 0.9544 - val_loss: 0.1494 - val_fn: 5.0000 - val_fp: 1345.0000 - val_tn: 55541.0000 - val_tp: 70.0000 - val_precision: 0.0495 - val_recall: 0.9333 - 7s/epoch - 64ms/step\n",
            "Epoch 19/30\n",
            "112/112 - 5s - loss: 6.1354e-07 - fn: 7.0000 - fp: 5292.0000 - tn: 222137.0000 - tp: 410.0000 - precision: 0.0719 - recall: 0.9832 - val_loss: 0.0225 - val_fn: 9.0000 - val_fp: 424.0000 - val_tn: 56462.0000 - val_tp: 66.0000 - val_precision: 0.1347 - val_recall: 0.8800 - 5s/epoch - 47ms/step\n",
            "Epoch 20/30\n",
            "112/112 - 7s - loss: 9.7046e-07 - fn: 12.0000 - fp: 5951.0000 - tn: 221478.0000 - tp: 405.0000 - precision: 0.0637 - recall: 0.9712 - val_loss: 0.0545 - val_fn: 6.0000 - val_fp: 821.0000 - val_tn: 56065.0000 - val_tp: 69.0000 - val_precision: 0.0775 - val_recall: 0.9200 - 7s/epoch - 59ms/step\n",
            "Epoch 21/30\n",
            "112/112 - 6s - loss: 6.6070e-07 - fn: 8.0000 - fp: 5377.0000 - tn: 222052.0000 - tp: 409.0000 - precision: 0.0707 - recall: 0.9808 - val_loss: 0.0547 - val_fn: 6.0000 - val_fp: 1094.0000 - val_tn: 55792.0000 - val_tp: 69.0000 - val_precision: 0.0593 - val_recall: 0.9200 - 6s/epoch - 51ms/step\n",
            "Epoch 22/30\n",
            "112/112 - 6s - loss: 1.1003e-06 - fn: 10.0000 - fp: 6201.0000 - tn: 221228.0000 - tp: 407.0000 - precision: 0.0616 - recall: 0.9760 - val_loss: 0.0534 - val_fn: 8.0000 - val_fp: 677.0000 - val_tn: 56209.0000 - val_tp: 67.0000 - val_precision: 0.0901 - val_recall: 0.8933 - 6s/epoch - 49ms/step\n",
            "Epoch 23/30\n",
            "112/112 - 7s - loss: 6.0926e-07 - fn: 8.0000 - fp: 4399.0000 - tn: 223030.0000 - tp: 409.0000 - precision: 0.0851 - recall: 0.9808 - val_loss: 0.0264 - val_fn: 9.0000 - val_fp: 434.0000 - val_tn: 56452.0000 - val_tp: 66.0000 - val_precision: 0.1320 - val_recall: 0.8800 - 7s/epoch - 61ms/step\n",
            "Epoch 24/30\n",
            "112/112 - 5s - loss: 6.9397e-07 - fn: 5.0000 - fp: 4334.0000 - tn: 223095.0000 - tp: 412.0000 - precision: 0.0868 - recall: 0.9880 - val_loss: 0.0367 - val_fn: 10.0000 - val_fp: 381.0000 - val_tn: 56505.0000 - val_tp: 65.0000 - val_precision: 0.1457 - val_recall: 0.8667 - 5s/epoch - 47ms/step\n",
            "Epoch 25/30\n",
            "112/112 - 7s - loss: 4.5462e-07 - fn: 2.0000 - fp: 2502.0000 - tn: 224927.0000 - tp: 415.0000 - precision: 0.1423 - recall: 0.9952 - val_loss: 0.0312 - val_fn: 9.0000 - val_fp: 614.0000 - val_tn: 56272.0000 - val_tp: 66.0000 - val_precision: 0.0971 - val_recall: 0.8800 - 7s/epoch - 64ms/step\n",
            "Epoch 26/30\n",
            "112/112 - 5s - loss: 3.7683e-07 - fn: 4.0000 - fp: 3504.0000 - tn: 223925.0000 - tp: 413.0000 - precision: 0.1054 - recall: 0.9904 - val_loss: 0.0280 - val_fn: 8.0000 - val_fp: 518.0000 - val_tn: 56368.0000 - val_tp: 67.0000 - val_precision: 0.1145 - val_recall: 0.8933 - 5s/epoch - 47ms/step\n",
            "Epoch 27/30\n",
            "112/112 - 7s - loss: 3.0584e-07 - fn: 3.0000 - fp: 3194.0000 - tn: 224235.0000 - tp: 414.0000 - precision: 0.1147 - recall: 0.9928 - val_loss: 0.3497 - val_fn: 7.0000 - val_fp: 3408.0000 - val_tn: 53478.0000 - val_tp: 68.0000 - val_precision: 0.0196 - val_recall: 0.9067 - 7s/epoch - 61ms/step\n",
            "Epoch 28/30\n",
            "112/112 - 6s - loss: 1.4163e-06 - fn: 8.0000 - fp: 5435.0000 - tn: 221994.0000 - tp: 409.0000 - precision: 0.0700 - recall: 0.9808 - val_loss: 0.1306 - val_fn: 6.0000 - val_fp: 2406.0000 - val_tn: 54480.0000 - val_tp: 69.0000 - val_precision: 0.0279 - val_recall: 0.9200 - 6s/epoch - 49ms/step\n",
            "Epoch 29/30\n",
            "112/112 - 6s - loss: 7.2025e-07 - fn: 6.0000 - fp: 4793.0000 - tn: 222636.0000 - tp: 411.0000 - precision: 0.0790 - recall: 0.9856 - val_loss: 0.0539 - val_fn: 7.0000 - val_fp: 790.0000 - val_tn: 56096.0000 - val_tp: 68.0000 - val_precision: 0.0793 - val_recall: 0.9067 - 6s/epoch - 58ms/step\n",
            "Epoch 30/30\n",
            "112/112 - 6s - loss: 8.4895e-07 - fn: 7.0000 - fp: 5626.0000 - tn: 221803.0000 - tp: 410.0000 - precision: 0.0679 - recall: 0.9832 - val_loss: 0.0254 - val_fn: 13.0000 - val_fp: 269.0000 - val_tn: 56617.0000 - val_tp: 62.0000 - val_precision: 0.1873 - val_recall: 0.8267 - 6s/epoch - 53ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6c55d99f60>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 66 of them as fraudulent\n",
        "- Missing 9 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 441 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why."
      ],
      "metadata": {
        "id": "x630FgwUFSOb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}