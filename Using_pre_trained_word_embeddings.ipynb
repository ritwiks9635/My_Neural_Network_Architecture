{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/My_Neural_Network_Architecture/blob/main/Using_pre_trained_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Using pre-trained word embeddings**"
      ],
      "metadata": {
        "id": "njSAUtps4prS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we show how to train a text classification model that uses pre-trained\n",
        "word embeddings.\n",
        "\n",
        "We'll work with the Newsgroup20 dataset, a set of 20,000 message board messages\n",
        "belonging to 20 different topic categories.\n",
        "\n",
        "For the pre-trained word embeddings, we'll use\n",
        "[GloVe embeddings](http://nlp.stanford.edu/projects/glove/)."
      ],
      "metadata": {
        "id": "ygS86ktep5QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Only the TensorFlow backend supports string inputs.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "4Xd8LMp-4tL7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ],
      "metadata": {
        "id": "2_IPMvqm419n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN4N78HM470R",
        "outputId": "70fec6a3-4415-4304-ea6e-7fbcf39b9d6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['soc.religion.christian', 'sci.med', 'sci.crypt', 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'rec.sport.hockey', 'comp.windows.x', 'comp.sys.mac.hardware', 'talk.religion.misc', 'sci.space', 'talk.politics.mideast', 'comp.graphics', 'sci.electronics', 'misc.forsale', 'talk.politics.misc', 'rec.autos', 'comp.os.ms-windows.misc', 'rec.motorcycles', 'alt.atheism', 'talk.politics.guns']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38965', '39050', '38626', '38561', '38730']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_dir / \"comp.windows.x\")[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ZiZRRC7fGq",
        "outputId": "74bd3225-9105-416b-8e62-153ed13a631a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['67378', '67557', '68176', '68213', '66445']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(open(data_dir / \"comp.windows.x\"/ \"67260\").read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De38Q79J5mn4",
        "outputId": "535e3285-52f6-45dc-af7a-97c664e0f372"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu comp.windows.x.motif:16776 comp.windows.x:67260 comp.human-factors:4654 comp.windows.ms:36407 comp.windows.open-look:8416\n",
            "Newsgroups: comp.windows.x.motif,comp.windows.x,comp.human-factors,comp.windows.ms,comp.windows.open-look\n",
            "Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!zaphod.mps.ohio-state.edu!rphroy!kocrsv01!c2xjfa\n",
            "From: c2xjfa@kocrsv01.delcoelect.com (James F Allman III)\n",
            "Subject: Re: GUI Study\n",
            "Message-ID: <1993Apr23.201024.13895@kocrsv01.delcoelect.com>\n",
            "Originator: c2xjfa@koptsw18\n",
            "Sender: news@kocrsv01.delcoelect.com (Usenet News Account)\n",
            "Organization: Delco Electronics Corp.\n",
            "References: <1993Apr2.203400.15357@kocrsv01.delcoelect.com> <1993Apr7.144905.9827@thunder.mcrcim.mcgill.edu> <1993Apr13.104408.24613@mnemosyne.cs.du.edu> <1993Apr23.031744.19111@mercury.unt.edu>\n",
            "Distribution: na\n",
            "Date: Fri, 23 Apr 1993 20:10:24 GMT\n",
            "Lines: 33\n",
            "\n",
            "\n",
            "In article <1993Apr23.031744.19111@mercury.unt.edu>, seth@ponder.csci.unt.edu (Seth Buffington) writes:\n",
            "> >Cutsie little Macintrash-like icons that are an instant recipe for\n",
            "> >mousitis IMHO. System 7 is undoubtedly the worst GUI I have used (out of\n",
            "> >that, RISCOS, MSWombles, and X11) simply because it does not provide enough\n",
            "> >keyboard shortcuts. Windows I must confess I quite like (cover your ears\n",
            "> >:-) ) because you can actually use it without having to ever touch the\n",
            "> >mouse.\n",
            "> [stuff delete]\n",
            "> >the user rather than making things _easier_ - and there should always be\n",
            "> >the option to do it your way if you want to, which is why I like the\n",
            "> >UNIX/X combination so much - it's so customizable. \n",
            "> \n",
            "> Hear! Hear! I agree completely. One thing I can't stand about\n",
            "> the Mac interface is its shear determination to FORCE you to use\n",
            "> the mouse(what if your mouse breaks--your whole system is\n",
            "> down!).  I like the mouse--it is handy on some occassions such\n",
            "> as cut and past and moving icons around, etc.  But for most\n",
            "> work, the keyboard and hot keys are 10-20 times faster than\n",
            "> using the mouse. Sure it is a plus to be able to do something\n",
            "> simple if you are an inexperienced user, but how long is it\n",
            "> before your are experienced? A month? Two? (Speaking of PCs at\n",
            "> the moment.)\n",
            "> \tI don't think it is too much to ask that window\n",
            "> programmers provide not only a menu/mouse interface but also\n",
            "> look forward to those who would like to move on to hot keys and\n",
            "> command line interfaces, which usually allows you to do more in\n",
            "> less time IF you are experienced.\n",
            "> \tAll of the above equally applies to windowing systems on\n",
            "> UNIX (especially since Unix is at least 500% more powerful than\n",
            "> DOS).\n",
            "> \n",
            "And at least 500% more user unfriendly as well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there are header lines that are leaking the file's category, either\n",
        "explicitly (the first line is literally the category name), or implicitly, e.g. via the\n",
        "`Organization` filed. Let's get rid of the headers:"
      ],
      "metadata": {
        "id": "sOfTZ6kVqGIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(f\"processing {dirname}, {len(fnames)} files found\")\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding = \"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcJGgx0EfIJD",
        "outputId": "40bfb9b3-a02a-4df9-c04e-3839221f3c90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing alt.atheism, 1000 files found\n",
            "processing comp.graphics, 1000 files found\n",
            "processing comp.os.ms-windows.misc, 1000 files found\n",
            "processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "processing comp.sys.mac.hardware, 1000 files found\n",
            "processing comp.windows.x, 1000 files found\n",
            "processing misc.forsale, 1000 files found\n",
            "processing rec.autos, 1000 files found\n",
            "processing rec.motorcycles, 1000 files found\n",
            "processing rec.sport.baseball, 1000 files found\n",
            "processing rec.sport.hockey, 1000 files found\n",
            "processing sci.crypt, 1000 files found\n",
            "processing sci.electronics, 1000 files found\n",
            "processing sci.med, 1000 files found\n",
            "processing sci.space, 1000 files found\n",
            "processing soc.religion.christian, 997 files found\n",
            "processing talk.politics.guns, 1000 files found\n",
            "processing talk.politics.mideast, 1000 files found\n",
            "processing talk.politics.misc, 1000 files found\n",
            "processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's actually one category that doesn't have the expected number of files, but the\n",
        "difference is small enough that the problem remains a balanced classification problem.\n",
        "\n",
        "\n",
        "\n",
        "## Shuffle and split the data into training & validation sets"
      ],
      "metadata": {
        "id": "1MyaYUwxqWWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "metadata": {
        "id": "fXWMacNkjeWd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a vocabulary index\n",
        "\n",
        "Let's use the `TextVectorization` to index the vocabulary found in the dataset.\n",
        "Later, we'll use the same layer instance to vectorize the samples.\n",
        "\n",
        "Our layer will only consider the top 20,000 words, and will truncate or pad sequences to\n",
        "be actually 200 tokens long."
      ],
      "metadata": {
        "id": "Vyb5XaZ8qgX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = layers.TextVectorization(max_tokens = 20000, output_sequence_length = 200)\n",
        "text_ds = tf_data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "7vDPGoDLj27Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer([\"the cat is a black or dog is white\"]).numpy()[0,:9]"
      ],
      "metadata": {
        "id": "rFUj3F4tk2-C",
        "outputId": "ecb4bf2d-c6bc-49c0-8fd1-c756308de170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3567,    8,    5,  570,   22, 1811,    8,  627])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, \"the\" gets represented as \"2\". Why not 0, given that \"the\" was the first\n",
        "word in the vocabulary? That's because index 0 is reserved for padding and index 1 is\n",
        "reserved for \"out of vocabulary\" tokens.\n",
        "\n",
        "Here's a dict mapping words to their indices:"
      ],
      "metadata": {
        "id": "tz9tVuiEqqLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "8vFlsEGCmCuD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[i] for i in text]"
      ],
      "metadata": {
        "id": "84IGc0VemfDd",
        "outputId": "d2247b8d-ad96-4920-98dc-ba66cadb1bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3567, 1819, 15, 2, 5818]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained word embeddings\n",
        "\n",
        "\n",
        "\n",
        "Let's download pre-trained GloVe embeddings (a 822M zip file).\n",
        "\n",
        "You'll need to run the following commands:"
      ],
      "metadata": {
        "id": "k--_Idutqj0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "huN8azExm4zG",
        "outputId": "29663fa5-0ccd-4a08-93f2-929c43a0a867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-06 05:38:25--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  4.71MB/s    in 2m 41s  \n",
            "\n",
            "2023-12-06 05:41:06 (5.11 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The archive contains text-encoded vectors of various sizes: 50-dimensional,\n",
        "100-dimensional, 200-dimensional, 300-dimensional. We'll use the 100D ones.\n",
        "\n",
        "Let's make a dict mapping words (strings) to their NumPy vector representation:"
      ],
      "metadata": {
        "id": "2aX9xv_ZqyN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "COl35fvNm_OA",
        "outputId": "5379614e-581c-4df5-abd2-dcde8c15ad43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's prepare a corresponding embedding matrix that we can use in a Keras\n",
        "`Embedding` layer. It's a simple NumPy matrix where entry at index `i` is the pre-trained\n",
        "vector for the word of index `i` in our `vectorizer`'s vocabulary."
      ],
      "metadata": {
        "id": "epLXzmDZq4dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "WxTGuFD9nHRF",
        "outputId": "a50076c4-3a48-44fd-8390-8801f79eab6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 17971 words (2029 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we load the pre-trained word embeddings matrix into an `Embedding` layer.\n",
        "\n",
        "Note that we set `trainable=False` so as to keep the embeddings fixed (we don't want to\n",
        "update them during training)."
      ],
      "metadata": {
        "id": "znO4CcYNq9_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(num_tokens, embedding_dim, trainable = False)\n",
        "\n",
        "embedding_layer.build((1,))\n",
        "embedding_layer.set_weights([embedding_matrix])"
      ],
      "metadata": {
        "id": "mv3fF82znPo_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pcG1XRNMn6Dd",
        "outputId": "84a59140-8055-4be1-808d-e333d8c2af60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000200   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 128)         64128     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, None, 128)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, None, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2247516 (8.57 MB)\n",
            "Trainable params: 247316 (966.08 KB)\n",
            "Non-trainable params: 2000200 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "First, convert our list-of-strings data to NumPy arrays of integer indices. The arrays\n",
        "are right-padded."
      ],
      "metadata": {
        "id": "OtG0CnzjrM7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "metadata": {
        "id": "SsmVKTUFn_J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use categorical crossentropy as our loss since we're doing softmax classification.\n",
        "Moreover, we use `sparse_categorical_crossentropy` since our labels are integers."
      ],
      "metadata": {
        "id": "3_BXG1j3rKVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "js72v8XmoGCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export an end-to-end model\n",
        "\n",
        "Now, we may want to export a `Model` object that takes as input a string of arbitrary\n",
        "length, rather than a sequence of indices. It would make the model much more portable,\n",
        "since you wouldn't have to worry about the input preprocessing pipeline.\n",
        "\n",
        "Our `vectorizer` is actually a Keras layer, so it's simple:"
      ],
      "metadata": {
        "id": "3KXd1csPrcCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model(\n",
        "    keras.ops.convert_to_tensor(\n",
        "        [[\"this message is about computer graphics and 3D modeling\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(class_names[np.argmax(probabilities[0])])"
      ],
      "metadata": {
        "id": "Ie5utHHqptbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}